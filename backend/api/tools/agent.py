
from smolagents import CodeAgent, LiteLLMModel, WebSearchTool

from context_building import build_context
from smolagents import LiteLLMModel

DEBUG = True

class Agent:
  fixed_questions:list[dict] = None
  models:dict = None

  def init(self, fixed_questions):
    self.fixed_questions = fixed_questions
    define_models(self)
  
  def forward(self, body: list[dict]) -> list[dict]:
    """
    Processes the input body and returns a response based on the agent's logic.

    Args:
        body (list[dict]): The input body containing user messages and other relevant information.

    Returns:
        list[dict]: The response generated by the agent.
    """
    # Here you would implement the logic to process the body and generate a response
    if len(body) == 0:
       return [{"balise": None, "text": None}]
    translated_body = translate_json(body)
    anthropified_body = anthropify_body(translated_body)
    context = build_context(anthropified_body)
    # Context is user/assistant alternating messages
    context[-1]["content"] = "### ORIGINAL USER PROMPT ###\n" + context[-1]["content"] + "\n### SYSTEM PROMPT ###\n" + "Do not talk to the user. Your output will be the prompt of another AI agent. You have to analyze all the context that is given to you and reduce it to a single string. This string should contain the most important information that the user has given you, and that you have given to the user. It should be a summary of the conversation, and it should be short while still being informative. The context you produce will be the prompt to another ageint, so it should contain all the relevant information about the user's state and the conversation history. Most importantly, you should take a lot of care about whether the user would be interested in a course explanation or a question to verify their understanding. Do include as much information as possible about the user's state for example."
    manager = self.models["manager"]
    prompt_manager = self.models["context_to_prompt"].generate(context).content

    answer = manager.run(prompt_manager + "\n\n### SYSTEM PROMPT ###\n Your  task is to analyze the context and decide which agent to use. If you think the user needs help with the course, ask course_agent to give you a paragraph about a specific topic you will ask it about, and return it. If you think it would be good for the user to confirm their knowledge, ask question_agent to ask a question about the course. Return an answer after a single tool use, so that your returned answer is of the form '{\"balise\": agent_used_type (cours or question), \"text\": content_to_return}' ")
    print(answer)
    # Returns a {"text":..., "balise":...}
    return answer

agent = Agent()

def init_agent(fixed_questions: list[dict]):
  agent.init(fixed_questions)

def run_agent(body: list[dict]) -> list[dict]:
   return agent.forward(body)

def define_models(agent) -> dict:
  models = dict()
  with open("./api_key.txt", "r") as f:
    api_key = f.read().strip()

  models["context_to_prompt"] = LiteLLMModel(model_id="claude-3-5-haiku-latest", api_key=api_key, temperature=0.2, max_tokens=5000)
  
  models["course"] = CodeAgent(model=LiteLLMModel(model_id="claude-sonnet-4-20250514", api_key=api_key, temperature=0.2, max_tokens=2000), name="course_agent", description="This Agent is responsible for explaining large concepts to the user. If the user seems stuck on some specific content, the course_agent would be interesting to use to explain the user the concept he is lacking.  It is also used to answer the user's questions about the course, such as 'What is a Markov Chain?' or 'What is Young's double-slit experiment?'. The course_agent is also used to explain the course step by step, and to answer the user's questions about the course.", tools=[WebSearchTool()], max_steps=3)

  models["question"] = CodeAgent(model=LiteLLMModel(model_id="claude-sonnet-4-20250514", api_key=api_key, temperature=0.2, max_tokens=2000), name="question_agent", description="This Agent is responsible for asking questions to the user to verify the users understanding of the course. When the user seems to have understood the course, the question_agent will ask questions to verify the user's understanding. If the user seems to be stuck on some specific content, the question_agent will ask questions to help the user understand the concept he is lacking. The question_agent is also used to ask questions about the user's understanding of the course, such as 'Do you feel like you completely understand what a Markov Chain is?' or 'Do you know the principle behind Young's double-slit experiment?'.", tools=[WebSearchTool()], max_steps=3)

  models["manager"] = CodeAgent(model=LiteLLMModel(model_id="claude-sonnet-4-20250514", api_key=api_key, temperature=0.1, max_tokens=300), managed_agents=[models["course"], models["question"]], name="manager_agent", description="This Agent is responsible for managing the conversation between the user and the course_agent and question_agent. It decides which agent to use based on the user's input and the context of the conversation. The manager_agent can also choose not to do anything if it believes it wouldn't help the user, or the user did not write enough to warrant an answer.", tools=[], max_steps=5)

  agent.models = models

def question_agent (context : str) -> str:
  """
  determines if enough inital questions have been asked to start the conversation, if not, it will ask the user a question
  """
  api_key = open(r"backend\api\tools\storage\api_key.txt", "r", encoding="utf-8").read()
  model = LiteLLMModel(
    model_id="anthropic/claude-opus-4-20250514",
    temperature=1,
    api_key= api_key# in practice we would not hardcode the API key, but use an environment variable or a secure vault service
  )
  
  prompt = """
Role: You're a tutor AI determining if enough context has been gathered to begin teaching.  
Rules:  
1. Analyze ONLY the conversation history below  
2. If essential teaching context is present (subject, level, etc..):  
   - Output EXACTLY: `%Question_end%`  
   - Do not be strict, but ensure the context is sufficient to start teaching
3. If a CRITICAL and ESSENTIAL information is missing:  
   - Output ONE question to gather the MOST URGENT missing information  
   - Phrase it as a SINGLE question only (no prefixes/suffixes)  

Conversation History CONSIDER THE FOLLOWING ONLY, IMPORTANT:  
{history}  

Output Instructions:  
- ONLY `%Question_end%` or ONE question  
- NO explanations, NO markdown, NO apologies  
- Example valid outputs:  
    -`%Question_end%`  
    -`What specific topic in algebra do you need help with?`  
    -`Are you preparing for an exam or just general practice?`  
"""
  prompt = str(prompt.format(history = context))
  return model(
     messages = [{"role": "user", "content": prompt}],
      max_tokens=1000
  ).content


def translate_json(body: list[dict]) -> list[dict]:
    # Gets dict, ordonned by keys and put into list
    translated = []
    for k in sorted(body.keys()):
       translated.append({"balise": body[k]["balise"], "content": body[k]["content"]})
    return translated

def anthropify_body(body: list[dict]) -> list[dict]:
    """
    Converts the body to a format suitable for anthropic models.
    """
    new_body = []
    if body[0]["balise"] != "user":
      new_body = [{"role": "user", "content": "Hello, I am a user. I would like to work on something."}]
    for message in body:
        if message["balise"] == "user":
            if len(new_body)==0 or new_body[-1]["role"] == "assistant":
               new_body.append({"role": "user", "content": message["content"]})
            else:
               new_body[-1]["content"] += "\n" + message["content"]
        else:
            # If message is not from the user, include balise
            assistant_content = "### " + message["balise"] + " ###\n" + message["content"]
            if len(new_body)==0 or new_body[-1]["role"] == "user":
                new_body.append({"role": "assistant", "content": assistant_content})
            else:
                new_body[-1]["content"] += "\n" + assistant_content

    return new_body


if __name__ == "__main__":
    # Example usage
    body = {0: {"balise": "question", "content": "What would you like to work on today?"}, 1: {"balise": "user", "content": "I'm working on Markov Chains but I'm doing well! I'd love to work on them a bit to refresh my memory."}}
    init_agent([])
    print(run_agent(body))
