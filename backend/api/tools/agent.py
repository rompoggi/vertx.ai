# /usr/bin/python3
from smolagents import CodeAgent, LiteLLMModel, WebSearchTool
from .context_building import build_context
import os
from os import path

DEBUG = True

import dotenv

dotenv.load_dotenv()

api_key: str = os.getenv("API_KEY", "")
if api_key == "":  # api_key should be globally defined TODO
    try:
        with open(
            path.join(path.dirname(__file__), "storage", "api_key.txt"), "r"
        ) as f:
            api_key = f.read().strip()
    except:
        print(
            "No file 'storage/api_key.txt', please create such a file (soon deprecated) or create a .env in /backend folder and add a '.env' file."
        )


def define_models() -> dict:
    return None

def log(message: str):
   with open("log.txt", "a") as f:
      f.write(message + "\n")

class Agent:
  fixed_questions: list[dict] = None
  fixed_context: list[dict] = None
  models: dict = None
  initialized: bool = False

  def init(self, fixed_questions):
    self.fixed_questions = fixed_questions
    define_models(self)

    # Add fixed questions as initial context
    fixed_context = []
    for fq in self.fixed_questions:
      # Add the question as assistant message
      fixed_context.append({"role": "assistant", "content": fq["question"]})
      # Add the answer as user message
      fixed_context.append({"role": "user", "content": fq["answer"]})
    self.fixed_context = fixed_context

    with open("log.txt", "w") as f:
       f.write(f"Agent initializated with fixed questions: {fixed_questions}.\n")

  def forward(self, body: list[dict]) -> list[dict]:
     # if "[%QE%]" is somewhere in the body, forward to manager, otherwise forward to question
     # Input is of form  [{"balise": "question", "content": "some text"}]
     # Output is of form [{"balise": "question", "text": "some text"}]

     if not self.initialized:
        self.init([])  # Initialize with empty fixed questions if not already initialized
        log("Agent not initialized, initializing with empty fixed questions.")

     if len(body) == 0:
       return [{"balise": None, "text": None}]

     log("Body:\n" + str(body))

     translated_body = translate_json(body)
     anthropified_body = anthropify_body(translated_body)
     body_with_fixed_context = self.fixed_context + anthropified_body
     context: str = self.stringify_context(body_with_fixed_context)

     log(f"\nContext built:\n {context}")

     if "[%QE%]" in context:
        log("Forwarding to manager due to [%QE%] in body.")
        return self.forward_manager(context)
     else:
        log("Forwarding to question agent.")
        return self.forward_question(context)
  
  def forward_question(self, context: str) -> list[dict]:
     question_returned = question_agent(context)
     return [{"balise": "question", "text": question_returned.content}]

  def forward_manager(self, context: str) -> list[dict]:
        """
        Processes the input body and returns a response based on the agent's logic.

        Args:
            body (list[dict]): The input body containing user messages and other relevant information.

        Returns:
            list[dict]: The response generated by the agent.
        """
      
        # Context is user/assistant alternating messages
        # Changed method of context building to just striify context 

        # context[-1]["content"] = "### ORIGINAL USER PROMPT ###\n" + context[-1]["content"] + "\n### SYSTEM PROMPT ###\n" + "Do not talk to the user. Your output will be the prompt of another AI agent. You have to analyze all the context that is given to you and reduce it to a single string. This string should contain the most important information that the user has given you, and that you have given to the user. It should be a summary of the conversation, and it should be short while still being informative. The context you produce will be the prompt to another ageint, so it should contain all the relevant information about the user's state and the conversation history. Most importantly, you should take a lot of care about whether the user would be interested in a course explanation or a question to verify their understanding. Do include as much information as possible about the user's state for example."
        manager = self.models["manager"]
        
        answer = manager.run(context + "\n\n### SYSTEM PROMPT ###\n Your  task is to analyze the context and decide which agent to use. If you think the user needs help with the course, ask course_agent to give you a paragraph about a specific topic you will ask it about, and return it. If you think it would be good for the user to confirm their knowledge, ask question_agent to ask a question about the course. Return an answer after a single tool use, so that your returned answer is of the form '{\"balise\": agent_used_type (cours or question), \"text\": content_to_return}'. If you don't want to return anything since the answers you are do not meet your quality standards, you may decide to return nothing, in this case, use the \"nothing\" balise. If an agent returns an answer you deem unwanted or unnecessary, or it does not meet your quality standards, you may decide to try again, ask another agent or, and it should sometimes be preferred, return nothing.")
        print(answer)
        # Returns a {"text":..., "balise":...}
        return answer
  
  def stringify_context(self, context: list[dict]) -> str:
    return "\n".join([f"### {msg['role']} ###\n{msg['content']}\n" for msg in context])

agent = Agent()


def init_agent(fixed_questions: list[dict]):
    """Initialize the agent with fixed questions from the questionnaire"""
    agent.init(fixed_questions)
    if DEBUG:
        print("Agent initialized with fixed questions:", fixed_questions)


def run_agent(body: list[dict]) -> list[dict]:
    return agent.forward(body)


def define_models(agent) -> dict:
    models = dict()
    # if (api_key == ""): # api_key should be globally defined TODO
    #   try:
    #     with open(path.join(path.dirname(__file__), "storage", "api_key.txt"), "r") as f:
    #       api_key = f.read().strip()
    #   except:
    #     print("No file 'storage/api_key.txt', please create such a file (soon deprecated) or create a .env in /backend folder and add a '.env' file.")

    models["course"] = CodeAgent(
        model=LiteLLMModel(
            model_id="claude-sonnet-4-20250514",
            api_key=api_key,
            temperature=0.2,
            max_tokens=2000,
        ),
        name="course_agent",
        description="This Agent is responsible for explaining large concepts to the user. If the user seems stuck on some specific content, the course_agent would be interesting to use to explain the user the concept he is lacking.  It is also used to answer the user's questions about the course, such as 'What is a Markov Chain?' or 'What is Young's double-slit experiment?'. The course_agent is also used to explain the course step by step, and to answer the user's questions about the course.\n### PROMPTING METHOD ###\nAsk the course agent to NOT complain, NOT ask for more information on its task, NOT answer as a chatbot. The course agent SHOULD answer a paragraph about a SINGLE topic. It should only use web search if it cannot come up with any course content by itself or make sure he is right about a complex point. It can think about a full course but should only teach about ONE SINGLE point of the course, likely as a single paragraph; as you may decide to ask the agent for the follow-up paragraphs later.",
        tools=[WebSearchTool()],
        max_steps=3,
    )

    models["question"] = CodeAgent(
        model=LiteLLMModel(
            model_id="claude-sonnet-4-20250514",
            api_key=api_key,
            temperature=0.2,
            max_tokens=2000,
        ),
        name="question_agent",
        description="This Agent is responsible for asking questions to the user to verify the users understanding of the course. When the user seems to have understood the course, the question_agent will ask questions to verify the user's understanding. If the user seems to be stuck on some specific content, the question_agent will ask questions to help the user understand the concept he is lacking. The question_agent is also used to ask questions about the user's understanding of the course, such as 'Do you feel like you completely understand what a Markov Chain is?' or 'Do you know the principle behind Young's double-slit experiment?'. \n### PROMPTING METHOD ###\nAsk the question agent to NOT complain, NOT ask for more information on its task, NOT answer as a chatbot. The question agent SHOULD answer a SINGLE question. It should only use web search if it cannot come up with any question by itself or make sure he is right about a complex question. It can think about a full problem but should output ONE SINGLE question of this problem; as you may decide to ask the agent for the follow-up questions later.",
        tools=[WebSearchTool()],
        max_steps=3,
    )

    models["manager"] = CodeAgent(
        model=LiteLLMModel(
            model_id="claude-sonnet-4-20250514",
            api_key=api_key,
            temperature=0.1,
            max_tokens=300,
        ),
        managed_agents=[models["course"], models["question"]],
        name="manager_agent",
        description="This Agent is responsible for managing the conversation between the user and the course_agent and question_agent. It decides which agent to use based on the user's input and the context of the conversation. The manager_agent can also choose not to do anything if it believes it wouldn't help the user, or the user did not write enough to warrant an answer.",
        tools=[],
        max_steps=5,
    )

    agent.models = models


def question_agent(context: str) -> str:
    """
    determines if enough inital questions have been asked to start the conversation, if not, it will ask the user a question
    """
    # actual file is in "storage/"
    # if (api_key == ""): # api_key should be globally defined TODO
    #   try:
    #     with open(path.join(path.dirname(__file__), "storage", "api_key.txt"), "r") as f:
    #       api_key = f.read().strip()
    #   except:
    #     print("No file 'storage/api_key.txt', please create such a file (soon deprecated) or create a .env in /backend folder and add a '.env' file.")

    # with open(path.join(path.dirname(__file__), "storage", "api_key.txt"), "r") as f: api_key = f.read().strip()
    model = LiteLLMModel(
        model_id="anthropic/claude-opus-4-20250514",
        temperature=0.3,
        api_key=api_key,  # in practice we would not hardcode the API key, but use an environment variable or a secure vault service
    )

    prompt = """
  ### SYSTEM PROMPT ###
Role: You're a tutor AI determining if enough context has been gathered to begin teaching and writing courses for the student.
Rules:
1. Analyze ONLY the conversation history below
2. If essential teaching context is present (subject, level, etc..):
   - Output EXACTLY: [%QE%]
   - Do not be strict, but ensure the context is sufficient to start teaching
3. If a CRITICAL and ESSENTIAL information is missing:
   - Output ONE question to gather the MOST URGENT missing information
   - Phrase it as a SINGLE question only (no prefixes/suffixes)

Conversation History CONSIDER THE FOLLOWING ONLY, IMPORTANT:
### CONVERSATION HISTORY ###
{history}

### SYSTEM PROMPT ###
Output Instructions:
- RETURN ONLY the following 6 characters tag: [%QE%] or return a single question
- NO explanations, NO markdown, NO apologies
- Example valid outputs:
    -`[%QE%]`
    -`What specific topic in algebra do you need help with?`
    -`Are you interested in numerical methods or theoretical aspects of Markov Chains?`
"""
    prompt = str(prompt.format(history=context))
    return model(
        messages=[{"role": "user", "content": prompt}], max_tokens=1000
    ).content


def translate_json(body: list[dict]) -> list[dict]:
    # Gets dict, ordonned by keys and put into list
    translated = []
    for k in body:
       translated.append({"balise": k["balise"] if k["balise"] != "default" else "user", "content": k["text"]})
    return translated


def anthropify_body(body: list[dict]) -> list[dict]:
    """
    Converts the body to a format suitable for anthropic models.
    """
    new_body = []
    if len(body) == 0:
       return []
    if body[0]["balise"] != "user":
        new_body = [
            {
                "role": "user",
                "content": "Hello, I am a user. I would like to work on something.",
            }
        ]
    for message in body:
        if message["balise"] == "user":
            if len(new_body) == 0 or new_body[-1]["role"] == "assistant":
                new_body.append({"role": "user", "content": message["content"]})
            else:
                new_body[-1]["content"] += "\n" + message["content"]
        else:
            # If message is not from the user, include balise
            assistant_content = (
                "### " + message["balise"] + " ###\n" + message["content"]
            )
            if len(new_body) == 0 or new_body[-1]["role"] == "user":
                new_body.append({"role": "assistant", "content": assistant_content})
            else:
                new_body[-1]["content"] += "\n" + assistant_content

    return new_body


if __name__ == "__main__":
    # Example usage
    body = {
        0: {"balise": "question", "content": "What would you like to work on today?"},
        1: {
            "balise": "user",
            "content": "I'm working on Markov Chains but I'm doing well! I'd love to work on them a bit to refresh my memory.",
        },
    }
    init_agent([])
    print(run_agent(body))
